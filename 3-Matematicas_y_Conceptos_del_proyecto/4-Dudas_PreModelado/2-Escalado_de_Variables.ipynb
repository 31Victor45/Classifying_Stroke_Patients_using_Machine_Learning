{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417be355",
   "metadata": {},
   "source": [
    "# Escalado de Variables: ¿Por qué es Vital en Machine Learning?\n",
    "\n",
    "Imagina que tienes un dataset con dos variables:\n",
    "1. **Edad:** de 0 a 100 años.\n",
    "2. **Ingreso Anual:** de 0 a 1,000,000 USD.\n",
    "\n",
    "Para un algoritmo matemático, una diferencia de 1,000 USD en ingresos parece mucho más importante que una diferencia de 10 años de edad, simplemente porque el **número** es más grande. El escalado soluciona esto.\n",
    "\n",
    "## 1. Conceptos Principales\n",
    "\n",
    "### A. Normalización (Min-Max Scaling)\n",
    "Transforma los datos para que todos estén en el rango **[0, 1]**.\n",
    "$$x_{norm} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$\n",
    "* **Uso:** Útil cuando sabes que tus datos no siguen una distribución normal o cuando usas algoritmos como Redes Neuronales.\n",
    "\n",
    "### B. Estandarización (Z-Score Scaling)\n",
    "Transforma los datos para que tengan una **media de 0** y una **desviación estándar de 1**.\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "* **Uso:** Es más robusto y es el preferido para algoritmos que asumen distribuciones normales (como Regresión Lineal, Logística o SVM).\n",
    "\n",
    "## 2. ¿Por qué es importante? (Los 3 pilares)\n",
    "\n",
    "1. **Algoritmos Basados en Distancia:** Algoritmos como **KNN (K-Nearest Neighbors)** o **K-Means** calculan la distancia euclidiana entre puntos. Si una variable tiene una escala enorme, dominará por completo el cálculo de la distancia.\n",
    "2. **Gradiente Descendiente:** En modelos como la Regresión Logística o Redes Neuronales, el escalado ayuda a que el algoritmo de optimización (gradiente descendiente) converja mucho más rápido hacia el mínimo.\n",
    "3. **Regularización:** Si usas penalizaciones como **Lasso o Ridge**, el modelo castiga los coeficientes grandes. Si una variable no está escalada, su coeficiente será artificialmente pequeño o grande, confundiendo a la regularización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896e938",
   "metadata": {},
   "source": [
    "## 3. ¿Cuándo NO es necesario escalar?\n",
    "\n",
    "No todos los modelos lo requieren. Los modelos basados en **Árboles de Decisión** (como Random Forest o XGBoost) son \"invariantes a la escala\". \n",
    "\n",
    "Esto se debe a que el árbol toma decisiones basadas en umbrales (ej. \"¿Es el ingreso > 50,000?\"). Esa decisión no cambia si escalas el número; el corte se moverá proporcionalmente, pero la separación de los datos será la misma.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Un error común: Data Leakage (Fuga de datos)\n",
    "\n",
    "Al escalar, **nunca** debes hacer `fit` sobre todo el dataset.\n",
    "1. Haces `fit` solo sobre los datos de **entrenamiento** (para aprender la media y desviación).\n",
    "2. Luego haces `transform` tanto en **entrenamiento** como en **test**.\n",
    "\n",
    "Si haces `fit` sobre todo el dataset, la información del conjunto de prueba \"se filtra\" en el entrenamiento, y tus resultados serán falsamente optimistas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
