{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0617380b",
   "metadata": {},
   "source": [
    "# Selección de Variables: Regresión Múltiple y el Efecto \"Eclipse\"\n",
    "\n",
    "Cuando construimos un modelo, no basta con saber que una variable tiene una correlación alta. Necesitamos saber si esa variable aporta **información única** o si solo está \"reflejando\" el efecto de otra.\n",
    "\n",
    "## 1. El Concepto de \"Pesos Ajustados\" (Coeficientes Beta)\n",
    "\n",
    "En una regresión simple ($y = \\beta_0 + \\beta_1 x$), el coeficiente nos dice cuánto cambia $y$ por cada unidad de $x$. \n",
    "\n",
    "Pero en una **Regresión Múltiple**:\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n$$\n",
    "\n",
    "Los coeficientes $\\beta$ se convierten en **pesos ajustados**. Esto significa que $\\beta_1$ representa el efecto de $x_1$ sobre $y$ **manteniendo todas las demás variables constantes**. Es como si \"limpiáramos\" el efecto de las otras variables para ver el impacto puro de $x_1$.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. El Fenómeno del \"Eclipse\" (Multicolinealidad)\n",
    "\n",
    "A veces, una variable que parecía muy importante en una correlación simple, \"desaparece\" o se vuelve insignificante en una regresión múltiple. Esto sucede por dos razones:\n",
    "\n",
    "1. **Redundancia:** La variable no aporta nada nuevo que otra no haya explicado ya.\n",
    "2. **Mediación/Eclipsamiento:** Una variable \"X\" en realidad solo afecta a \"Y\" a través de una variable \"Z\". Cuando incluyes a \"Z\" en el modelo, \"X\" se queda sin \"luz\" (se eclipsa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80e616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlación Simple con la Nota:\n",
      "Nota         1.000000\n",
      "Estudio      0.873792\n",
      "Café         0.838317\n",
      "Capacidad    0.377399\n",
      "Name: Nota, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- SIMULACIÓN DIDÁCTICA ---\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "\n",
    "# Variable A: Horas de estudio (Influencia real)\n",
    "horas_estudio = np.random.normal(10, 2, n)\n",
    "\n",
    "# Variable B: Dinero gastado en café (Altamente correlacionada con horas de estudio, \n",
    "# pero no mejora la nota por sí sola)\n",
    "cafe = horas_estudio + np.random.normal(0, 0.5, n)\n",
    "\n",
    "# Variable C: Inteligencia/Capacidad previa (Influencia real)\n",
    "capacidad = np.random.normal(100, 15, n)\n",
    "\n",
    "# Variable Objetivo: Nota del examen\n",
    "# Nota = 2*(horas) + 0.1*(capacidad) + ruido (El café NO está en la fórmula real)\n",
    "nota = (2 * horas_estudio) + (0.05 * capacidad) + np.random.normal(0, 2, n)\n",
    "\n",
    "df = pd.DataFrame({'Nota': nota, 'Estudio': horas_estudio, 'Café': cafe, 'Capacidad': capacidad})\n",
    "\n",
    "# 1. Veamos la correlación simple\n",
    "print(\"Correlación Simple con la Nota:\")\n",
    "print(df.corr()['Nota'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cbd630",
   "metadata": {},
   "source": [
    "## 3. Detectando el Eclipsamiento con el Modelo\n",
    "\n",
    "Si miras la correlación de arriba, el **Café** parece tener una relación fuerte con la **Nota**. Un analista novato diría: \"¡Beber café sube las notas!\". \n",
    "\n",
    "Vamos a ajustar el modelo múltiple para ver si el Café sobrevive cuando \"controlamos\" por las Horas de Estudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "089340c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   Nota   R-squared:                       0.810\n",
      "Model:                            OLS   Adj. R-squared:                  0.804\n",
      "Method:                 Least Squares   F-statistic:                     136.3\n",
      "Date:                Wed, 31 Dec 2025   Prob (F-statistic):           1.75e-34\n",
      "Time:                        18:58:41   Log-Likelihood:                -196.78\n",
      "No. Observations:                 100   AIC:                             401.6\n",
      "Df Residuals:                      96   BIC:                             412.0\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.5896      1.359      1.170      0.245      -1.108       4.287\n",
      "Estudio        1.9757      0.376      5.253      0.000       1.229       2.722\n",
      "Café          -0.1530      0.376     -0.407      0.685      -0.899       0.593\n",
      "Capacidad      0.0536      0.011      4.817      0.000       0.032       0.076\n",
      "==============================================================================\n",
      "Omnibus:                        1.353   Durbin-Watson:                   1.821\n",
      "Prob(Omnibus):                  0.508   Jarque-Bera (JB):                1.317\n",
      "Skew:                           0.169   Prob(JB):                        0.518\n",
      "Kurtosis:                       2.551   Cond. No.                         794.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Definimos X (predictores) y agregamos una constante (el intercepto)\n",
    "X = df[['Estudio', 'Café', 'Capacidad']]\n",
    "X = sm.add_constant(X)\n",
    "y = df['Nota']\n",
    "\n",
    "# Ajustamos el modelo\n",
    "modelo = sm.OLS(y, X).fit()\n",
    "\n",
    "print(modelo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0091997",
   "metadata": {},
   "source": [
    "## 4. Cómo interpretar los resultados para decidir qué variable dejar\n",
    "\n",
    "Para saber si una variable influye verdaderamente o está eclipsada, miramos tres cosas en la tabla de resultados anterior:\n",
    "\n",
    "1. **P-valor del Coeficiente ($P > |t|$):** * Si es $< 0.05$, la variable aporta información **única** que las demás no tienen.\n",
    "   * En nuestro ejemplo, verás que el p-valor del **Café** sube mucho (deja de ser significativo), mientras que el de **Estudio** se mantiene bajo. El Café ha sido \"eclipsado\".\n",
    "\n",
    "2. **VIF (Factor de Inflación de la Varianza):**\n",
    "   * Es la herramienta técnica para detectar el \"eclipse\". \n",
    "   * Si el VIF es $> 5$ o $10$, hay demasiada redundancia entre variables.\n",
    "\n",
    "3. **Cambio en los Coeficientes:**\n",
    "   * Si el coeficiente de una variable cambia drásticamente de signo o cae a casi cero al añadir otra variable, has detectado una variable \"eclipsadora\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0f6131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Análisis de Redundancia (VIF) ---\n",
      "    Variable        VIF\n",
      "1    Estudio  14.799920\n",
      "2       Café  14.746528\n",
      "3  Capacidad   1.037920\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calculamos el VIF para cada variable\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(\"\\n--- Análisis de Redundancia (VIF) ---\")\n",
    "print(vif_data[vif_data['Variable'] != 'const'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e289985d",
   "metadata": {},
   "source": [
    "### **Resumen Didáctico**\n",
    "\n",
    "1. La Correlación es como ver a dos personas caminando juntas; no sabes quién guía a quién.\n",
    "\n",
    "2. La Regresión Múltiple es como pedirle a una persona que se detenga para ver si la otra sigue caminando hacia el mismo lugar.\n",
    "\n",
    "3. Si una variable tiene un VIF alto y un P-valor alto en presencia de otras, es una candidata perfecta para ser eliminada: está eclipsada y solo añade ruido al modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
