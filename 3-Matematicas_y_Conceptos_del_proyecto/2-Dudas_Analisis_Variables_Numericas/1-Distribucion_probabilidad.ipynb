{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d4422d",
   "metadata": {},
   "source": [
    "# Análisis de la Forma de los Datos: Distribución, Skewness y Curtosis\n",
    "\n",
    "Cuando analizamos una variable numérica, no solo nos importa su promedio, sino cómo están repartidos los datos. A esto lo llamamos la **Distribución**.\n",
    "\n",
    "### 1. ¿Qué es la Distribución de una Variable?\n",
    "Es una función o gráfico (como un histograma) que muestra todos los valores posibles de los datos y con qué frecuencia ocurren. \n",
    "* Si los datos se agrupan perfectamente al centro, hablamos de una **Distribución Normal** (Campana de Gauss).\n",
    "* En el mundo real, los datos suelen estar \"estirados\" o \"amontonados\", y aquí es donde entran el Skewness y la Curtosis.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Skewness (Asimetría)\n",
    "El Skewness mide qué tan \"inclinada\" o desplazada está la distribución respecto al centro. Indica hacia dónde se estira la **cola** de los datos.\n",
    "\n",
    "* **Skewness = 0 (Simétrica):** La cola izquierda es igual a la derecha. La Media, Mediana y Moda coinciden.\n",
    "* **Skewness Positivo (Derecha):** La cola larga está a la derecha. Hay unos pocos valores muy grandes que \"jalan\" el promedio hacia arriba. (Ejemplo: Salarios de una empresa).\n",
    "* **Skewness Negativo (Izquierda):** La cola larga está a la izquierda. Hay unos pocos valores muy pequeños. (Ejemplo: Edad de jubilación).\n",
    "\n",
    "\n",
    "\n",
    "> **Regla didáctica:** \"La cola nos dice el nombre\". Si la cola apunta a los números positivos (derecha), el skewness es positivo.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Curtosis (Apuntamiento)\n",
    "La Curtosis mide qué tan \"puntiaguda\" es la distribución y, lo más importante en ML, qué tan pesadas son las **colas** (la probabilidad de encontrar valores extremos o *outliers*).\n",
    "\n",
    "Se interpreta comparándola con la Distribución Normal (que tiene Curtosis = 3 o Curtosis Excedente = 0):\n",
    "\n",
    "1.  **Mesocúrtica (Normal):** Distribución equilibrada.\n",
    "2.  **Leptocúrtica (Alta):** Muy puntiaguda. Las colas son \"gruesas\", lo que significa que hay una alta probabilidad de tener **valores extremos (outliers)**.\n",
    "3.  **Platicúrtica (Baja):** Distribución plana y dispersa. Las colas son delgadas; los valores están más repartidos y hay menos outliers extremos.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 4. ¿Cómo se interpretan en Machine Learning?\n",
    "\n",
    "### **Skewness**\n",
    "\n",
    "Los rangos de interpretación para el Skewness suelen ser:\n",
    "\n",
    "* **-0.5 a 0.5:** Distribución aproximadamente simétrica.\n",
    "* **-1 a -0.5 o 0.5 a 1:** Asimetría moderada.\n",
    "* **< -1 o > 1:** Asimetría altamente sesgada.\n",
    "\n",
    "### 1. ¿Por qué el Skewness > 0.8 es un problema?\n",
    "Cuando una variable tiene un sesgo fuerte (Skewness positivo), la **Media** se aleja de la **Mediana**. Muchos modelos de Machine Learning (como la Regresión Lineal o Redes Neuronales) asumen que los errores tienen una distribución normal. Si los datos están muy sesgados:\n",
    "1. El modelo será muy sensible a los valores extremos de la cola.\n",
    "2. Las predicciones en los rangos bajos/medios pueden perder precisión.\n",
    "\n",
    "### **Curtosis**\n",
    "\n",
    "| Métrica | Valor | Interpretación para tu Modelo |\n",
    "| :--- | :--- | :--- |\n",
    "| **Curtosis** | Alta (> 3) | ¡Cuidado! Tu modelo enfrentará muchos Outliers que pueden sesgar las predicciones. |\n",
    "| **Curtosis** | Baja (< 3) | Los datos son muy estables, pero quizás no hay una señal clara o centralizada. |\n",
    "\n",
    "### Resumen Visual\n",
    "* **Skewness:** ¿Hacia dónde se barre la basura (la cola)?\n",
    "* **Curtosis:** ¿Qué tan alta es la montaña y qué tan peligrosos son los extremos?\n",
    "\n",
    "### La Transformación Logarítmica: \"El compresor de colas\"\n",
    "Cuando aplicas $log(x)$ a una variable con sesgo positivo, sucede algo \"mágico\" estadísticamente:\n",
    "* Los valores grandes (en la cola derecha) se \"encogen\" o comprimen significativamente.\n",
    "* Los valores pequeños se mantienen relativamente similares o se expanden.\n",
    "* **Resultado:** La cola se acorta y la distribución se vuelve mucho más parecida a una Campana de Gauss (Normal).\n",
    "\n",
    "\n",
    "\n",
    "###  Otras transformaciones comunes\n",
    "Si el logaritmo no es suficiente o tienes valores de cero, existen otras opciones:\n",
    "\n",
    "| Transformación | Cuándo usarla | Fórmula |\n",
    "| :--- | :--- | :--- |\n",
    "| **Logarítmica** | Sesgo positivo fuerte | $\\log(x)$ o $\\log(x + 1)$ |\n",
    "| **Raíz Cuadrada** | Sesgo positivo moderado | $\\sqrt{x}$ |\n",
    "| **Box-Cox** | Solo para datos positivos ($>0$) | Busca automáticamente la mejor potencia $\\lambda$ |\n",
    "| **Yeo-Johnson** | Para datos positivos y negativos | Versión moderna y versátil de Box-Cox |\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Cuándo NO transformar?\n",
    "Aunque el Skewness sea > 0.8, no siempre debes transformar:\n",
    "* **Modelos de Árboles (Random Forest, XGBoost):** Estos modelos son \"invariantes a la escala\". No les importa el skewness porque dividen los datos basados en umbrales (orden), no en distancias.\n",
    "* **Interpretabilidad:** Si transformas la variable objetivo ($y$), recuerda que tus predicciones estarán en escala logarítmica y deberás aplicar la función inversa ($exp$) para explicárselas al negocio.\n",
    "\n",
    "> **Tip Pro:** Antes de decidir, calcula el Skewness, aplica la transformación en una columna temporal y vuelve a calcularlo. Si el nuevo valor está entre -0.5 y 0.5, ¡tu transformación fue un éxito!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
