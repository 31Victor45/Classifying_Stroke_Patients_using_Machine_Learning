{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c7f03e",
   "metadata": {},
   "source": [
    "# Validación de Supuestos: Test de Levene y Mann-Whitney U\n",
    "\n",
    "En Machine Learning, antes de confiar en una característica, debemos saber si los grupos que comparamos son estadísticamente \"parecidos\" en su dispersión o en su posición.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Test de Levene (Homocedasticidad)\n",
    "\n",
    "El test de Levene se utiliza para verificar si diferentes grupos tienen la misma **varianza** (es decir, si la dispersión de los datos es constante). A esta igualdad de varianzas se le llama **Homocedasticidad**.\n",
    "\n",
    "* **Hipótesis Nula ($H_0$):** Las varianzas son iguales en todos los grupos.\n",
    "* **Hipótesis Alternativa ($H_1$):** Al menos un grupo tiene una varianza distinta (**Heterocedasticidad**).\n",
    "\n",
    "**¿Por qué es vital en Machine Learning?**\n",
    "Si vas a usar modelos lineales (como Regresión Lineal o Logistic Regression), estos asumen que el error es constante. Si el Test de Levene da un **p-valor < 0.05**, significa que tus grupos son muy distintos en su dispersión, y podrías necesitar modelos más robustos o transformar la variable.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Prueba de Mann-Whitney U (La alternativa no paramétrica)\n",
    "\n",
    "¿Recuerdas el Test de Shapiro-Wilk? Si tus datos **NO** son normales, no puedes usar una prueba de T-Student para comparar promedios. En su lugar, usas **Mann-Whitney U**.\n",
    "\n",
    "Esta prueba no compara medias, sino que compara los **rangos** (la posición de los datos). Determina si es más probable que un valor extraído al azar de un grupo sea mayor que uno del otro grupo.\n",
    "\n",
    "* **Uso principal:** Comparar si hay una diferencia significativa entre dos grupos (ej. ¿Ganan más los del Depto. A que los del Depto. B?) cuando los datos están sesgados o tienen outliers.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a472c65",
   "metadata": {},
   "source": [
    "# La d de Cohen: Midiendo el Tamaño del Efecto\n",
    "\n",
    "Si la prueba de Mann-Whitney o la T de Student te dicen que \"hay una diferencia\", la **d de Cohen** te dice qué tan **grande** o importante es esa diferencia en términos prácticos.\n",
    "\n",
    "### 1. ¿Qué es exactamente?\n",
    "La d de Cohen mide la distancia entre las medias de dos grupos en unidades de **desviación estándar**. \n",
    "\n",
    "A diferencia del p-valor (que solo te dice si la diferencia es fruto del azar o no), la d de Cohen es una medida estandarizada que permite comparar resultados entre distintos estudios o diferentes variables.\n",
    "\n",
    "**La fórmula básica es:**\n",
    "$$d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{pooled}}$$\n",
    "\n",
    "Donde:\n",
    "* $\\bar{x}_1, \\bar{x}_2$: Son las medias de los grupos.\n",
    "* $s_{pooled}$: Es la desviación estándar combinada (un promedio de la dispersión de ambos).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Interpretación (Escala de Cohen)\n",
    "Jacob Cohen estableció una guía para entender qué tan fuerte es el efecto detectado:\n",
    "\n",
    "| Valor de d | Tamaño del Efecto | Interpretación Didáctica |\n",
    "| :--- | :--- | :--- |\n",
    "| **0.2** | Pequeño | La diferencia existe, pero las distribuciones se solapan muchísimo. |\n",
    "| **0.5** | Mediano | La diferencia es visible a simple vista en un gráfico. |\n",
    "| **0.8** | Grande | Las distribuciones están claramente separadas. |\n",
    "| **> 1.2** | Muy Grande | Los grupos son drásticamente diferentes. |\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 3. ¿Por qué es importante en Machine Learning?\n",
    "\n",
    "En ML, no solo buscamos variables que tengan un \"p-valor < 0.05\". Buscamos variables que tengan un **impacto real**.\n",
    "\n",
    "* **Feature Selection (Selección de Características):** Si tienes 100 variables que \"influyen\" según el p-valor, pero solo puedes usar 10 por eficiencia, elegirás aquellas con la **d de Cohen más alta**. Estas son las que realmente moverán la aguja en tus predicciones.\n",
    "* **Priorización de Negocio:** Imagina que un modelo detecta que un cambio en la interfaz aumenta las ventas. Si la d de Cohen es 0.1, el esfuerzo de desarrollo quizá no valga la pena, aunque sea \"estadísticamente significativo\".\n",
    "* **Validación de Modelos:** Si comparas dos modelos (A y B), la d de Cohen te ayuda a cuantificar cuánto mejor es uno frente al otro más allá de una simple resta de porcentajes.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
