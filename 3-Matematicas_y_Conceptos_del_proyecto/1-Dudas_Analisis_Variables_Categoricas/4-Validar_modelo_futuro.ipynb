{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec5ec6f",
   "metadata": {},
   "source": [
    "# Validación Empírica vs. Teoría Estadística\n",
    "\n",
    "Aunque $\\chi^2$ y la V de Cramer son herramientas poderosas para filtrar variables, no son infalibles. Por ello, crear modelos con y sin ciertas variables es una práctica recomendada que se formaliza bajo el concepto de **Estudios de Ablación**.\n",
    "\n",
    "### 1. ¿Por qué comparar modelos si la estadística dice que una variable es \"débil\"?\n",
    "Existen tres razones principales por las que un modelo podría necesitar una variable que parece \"despreciable\" estadísticamente:\n",
    "\n",
    "* **Interacciones No Lineales:** Chi-cuadrado mide la relación individual. Sin embargo, una variable \"débil\" combinada con otra podría crear una señal muy fuerte que el modelo de ML (especialmente árboles de decisión o redes neuronales) sí puede aprovechar.\n",
    "* **Reducción de Sesgo:** A veces, una variable con baja fuerza de asociación ayuda a \"ajustar\" pequeños sesgos en segmentos específicos de los datos.\n",
    "* **Contexto de Negocio:** Una variable puede tener poca fuerza estadística pero ser crucial para la explicabilidad o la confianza del usuario final en el modelo.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. El Estudio de Ablación (*Ablation Study*)\n",
    "\n",
    "Un **Estudio de Ablación** consiste en eliminar sistemáticamente un componente (una variable, una capa de una red neuronal, o un proceso de limpieza) para observar cómo afecta el rendimiento del sistema completo.\n",
    "\n",
    "> **Etimología:** El término viene de la medicina, donde se extirpa un tejido para entender su función. En ML, \"extirpamos\" una característica para entender su valor real.\n",
    "\n",
    "#### Pasos para tu experimento:\n",
    "1.  **Modelo Base (Baseline):** Entrenas el modelo con todas las variables seleccionadas por expertos.\n",
    "2.  **Modelo Reducido:** Entrenas el mismo modelo (mismos hiperparámetros) eliminando las variables con V de Cramer < 0.10.\n",
    "3.  **Comparativa de Métricas:** Evalúas ambos en un conjunto de *Test* independiente usando métricas como F1-Score, AUC-ROC o RMSE.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Matriz de Decisión: ¿Con cuál me quedo?\n",
    "\n",
    "Al comparar los dos modelos, te enfrentarás a este escenario:\n",
    "\n",
    "| Resultado del Experimento | Acción Recomendada | Justificación |\n",
    "| :--- | :--- | :--- |\n",
    "| **Rendimiento idéntico** | Usar modelo **Reducido** | Principio de Parsimonia (Navaja de Ockham): El modelo más simple es preferible si el resultado es igual. |\n",
    "| **Mejora significativa con variables débiles** | Usar modelo **Completo** | Hay interacciones complejas que la estadística bivariada no capturó. |\n",
    "| **Mejora eliminando variables débiles** | Usar modelo **Reducido** | Las variables eran puro \"ruido\" y estaban causando Overfitting. |\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Conclusión para tu flujo de trabajo\n",
    "No confíes ciegamente en un solo número. Usa Chi-cuadrado y Cramer para **priorizar**, pero usa el **Estudio de Ablación** para **decidir**. Un modelo con menos variables suele ser más fácil de mantener, más rápido en producción y menos propenso a errores de datos en el futuro."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
