{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf47ce59",
   "metadata": {},
   "source": [
    "# Balanceo de Clases: El Arte de Equilibrar la Balanza\n",
    "\n",
    "En un mundo ideal, tendríamos la misma cantidad de ejemplos para cada categoría. En la realidad, tenemos **Clases Desbalanceadas**. Para solucionar esto, existen dos técnicas clásicas: **Random Undersampling** y **Random Oversampling**.\n",
    "\n",
    "## 1. Random Undersampling (Submuestreo Aleatorio)\n",
    "\n",
    "Esta técnica consiste en **eliminar** ejemplos de la clase mayoritaria para igualarla con la minoritaria.\n",
    "\n",
    "* **Cómo funciona:** Si tienes 1,000 casos de \"Sanos\" y 100 de \"Enfermos\", el algoritmo elige al azar 100 casos de los \"Sanos\" y descarta los otros 900.\n",
    "* **La Analogía:** Es como si tuvieras una biblioteca con 1,000 libros de Historia y 10 de Arte. Para que el bibliotecario no se olvide del Arte, decides tirar a la basura 990 libros de Historia. Ahora tienes 10 y 10.\n",
    "\n",
    "## 2. Random Oversampling (Sobremuestreo Aleatorio)\n",
    "\n",
    "Esta técnica consiste en **duplicar** o triplicar ejemplos de la clase minoritaria hasta igualar a la mayoritaria.\n",
    "\n",
    "* **Cómo funciona:** Siguiendo el ejemplo anterior, tomamos los 100 casos de \"Enfermos\" y los copiamos 10 veces. Ahora tienes 1,000 \"Sanos\" y 1,000 \"Enfermos\" (aunque muchos son clones exactos).\n",
    "* **La Analogía:** Es como si fotocopiaras los 10 libros de Arte muchas veces hasta llenar el mismo espacio que los de Historia. Tienes muchos libros, pero la información sigue siendo la misma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9853e3",
   "metadata": {},
   "source": [
    "## 3. ¿Por qué NO se suelen recomendar (con frecuencia)?\n",
    "\n",
    "Aunque parecen soluciones rápidas y sencillas, los científicos de datos experimentados suelen evitarlas o usarlas con mucha cautela por razones muy serias:\n",
    "\n",
    "### El gran pecado del Undersampling: Pérdida de Información\n",
    "Al eliminar datos, estás tirando información valiosa a la basura. Esos 900 ejemplos de \"Sanos\" que borraste podrían tener detalles sutiles que ayudaban al modelo a distinguir casos difíciles. Estás haciendo a tu modelo más \"ignorante\" por decreto.\n",
    "\n",
    "### El gran pecado del Oversampling: Overfitting (Sobreajuste)\n",
    "Como estás duplicando exactamente los mismos datos, el modelo no está aprendiendo a generalizar qué es una \"Enfermedad\", sino que está **memorizando** esos 100 casos específicos. \n",
    "* El modelo se vuelve excelente con esos datos, pero cuando llega un paciente nuevo (que no es una copia idéntica), el modelo falla estrepitosamente.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. ¿Qué hacer en lugar de usar estas técnicas?\n",
    "\n",
    "Si el balanceo aleatorio es peligroso, ¿cómo atacamos el problema? Aquí los enfoques preferidos:\n",
    "\n",
    "1. **Cambiar la Métrica de Éxito:** No uses \"Accuracy\" (Precisión Global). Usa **F1-Score, Precisión, Recall** o el **Área bajo la curva ROC (AUC)**. Estas métricas no se dejan engañar por el tamaño de las clases.\n",
    "2. **SMOTE (Synthetic Minority Over-sampling Technique):** En lugar de copiar y pegar datos existentes, SMOTE crea datos \"nuevos\" pero parecidos, haciendo una interpolación matemática entre los puntos vecinos.\n",
    "3. **Pesos de Clase (Class Weights):** En lugar de cambiar los datos, le dices al modelo: *\"Cada vez que te equivoques con un 'Enfermo', la penalización será 10 veces mayor que si te equivocas con un 'Sano'\"*. El modelo aprende a prestar más atención sin perder información ni clonar datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
